{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30dc636c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0dc653",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.8/site-packages/tensorrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24ac0224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-27 14:41:13.762613: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-27 14:41:16.561773: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 14:41:16.561995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-27 14:41:16.562019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, SimpleRNN\n",
    "from keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee565b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"hidden_neurons = 50\\nmy_optimizer = \\\"sgd\\\"\\nbatch_size = 60\\nerror_function = \\\"mean_squared_error\\\"\\noutput_nonlinearity = \\\"softmax\\\"\\ncycles = 5\\nepochs_per_cycle = 3\\ncontext = 3\";\n",
       "                var nbb_formatted_code = \"hidden_neurons = 50\\nmy_optimizer = \\\"sgd\\\"\\nbatch_size = 60\\nerror_function = \\\"mean_squared_error\\\"\\noutput_nonlinearity = \\\"softmax\\\"\\ncycles = 5\\nepochs_per_cycle = 3\\ncontext = 3\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_neurons = 50\n",
    "my_optimizer = \"sgd\"\n",
    "batch_size = 60\n",
    "error_function = \"mean_squared_error\"\n",
    "output_nonlinearity = \"softmax\"\n",
    "cycles = 5\n",
    "epochs_per_cycle = 3\n",
    "context = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c5caad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def create_tesla_text_from_file(textfile=\\\"tesla.txt\\\"):\\n    clean_text_chunks = []\\n    with open(textfile, \\\"r\\\", encoding=\\\"utf-8\\\") as text:\\n        for line in text:\\n            clean_text_chunks.append(line)\\n            clean_text = (\\\"\\\".join(clean_text_chunks)).lower()\\n            text_as_list = clean_text.split()\\n    return text_as_list\\n\\n\\ntext_as_list = create_tesla_text_from_file()\";\n",
       "                var nbb_formatted_code = \"def create_tesla_text_from_file(textfile=\\\"tesla.txt\\\"):\\n    clean_text_chunks = []\\n    with open(textfile, \\\"r\\\", encoding=\\\"utf-8\\\") as text:\\n        for line in text:\\n            clean_text_chunks.append(line)\\n            clean_text = (\\\"\\\".join(clean_text_chunks)).lower()\\n            text_as_list = clean_text.split()\\n    return text_as_list\\n\\n\\ntext_as_list = create_tesla_text_from_file()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tesla_text_from_file(textfile=\"tesla.txt\"):\n",
    "    clean_text_chunks = []\n",
    "    with open(textfile, \"r\", encoding=\"utf-8\") as text:\n",
    "        for line in text:\n",
    "            clean_text_chunks.append(line)\n",
    "            clean_text = (\"\".join(clean_text_chunks)).lower()\n",
    "            text_as_list = clean_text.split()\n",
    "    return text_as_list\n",
    "\n",
    "\n",
    "text_as_list = create_tesla_text_from_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b189b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"distinct_words = set(text_as_list)\\nnumber_of_words = len(distinct_words)\\nword2index = dict((w, i) for i, w in enumerate(distinct_words))\\nindex2word = dict((i, w) for i, w in enumerate(distinct_words))\";\n",
       "                var nbb_formatted_code = \"distinct_words = set(text_as_list)\\nnumber_of_words = len(distinct_words)\\nword2index = dict((w, i) for i, w in enumerate(distinct_words))\\nindex2word = dict((i, w) for i, w in enumerate(distinct_words))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distinct_words = set(text_as_list)\n",
    "number_of_words = len(distinct_words)\n",
    "word2index = dict((w, i) for i, w in enumerate(distinct_words))\n",
    "index2word = dict((i, w) for i, w in enumerate(distinct_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4587ff7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def create_word_indices_for_text(text_as_list):\\n    input_words = []\\n    label_word = []\\n    for i in range(0, len(text_as_list) - context):\\n        input_words.append((text_as_list[i : i + context]))\\n        label_word.append((text_as_list[i + context]))\\n    return input_words, label_word\\n\\n\\ninput_words, label_word = create_word_indices_for_text(text_as_list)\";\n",
       "                var nbb_formatted_code = \"def create_word_indices_for_text(text_as_list):\\n    input_words = []\\n    label_word = []\\n    for i in range(0, len(text_as_list) - context):\\n        input_words.append((text_as_list[i : i + context]))\\n        label_word.append((text_as_list[i + context]))\\n    return input_words, label_word\\n\\n\\ninput_words, label_word = create_word_indices_for_text(text_as_list)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_word_indices_for_text(text_as_list):\n",
    "    input_words = []\n",
    "    label_word = []\n",
    "    for i in range(0, len(text_as_list) - context):\n",
    "        input_words.append((text_as_list[i : i + context]))\n",
    "        label_word.append((text_as_list[i + context]))\n",
    "    return input_words, label_word\n",
    "\n",
    "\n",
    "input_words, label_word = create_word_indices_for_text(text_as_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e29ff302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"input_vectors = np.zeros((len(input_words), context, number_of_words), dtype=np.int16)\\nvectorized_labels = np.zeros((len(input_words), number_of_words), dtype=np.int16)\";\n",
       "                var nbb_formatted_code = \"input_vectors = np.zeros((len(input_words), context, number_of_words), dtype=np.int16)\\nvectorized_labels = np.zeros((len(input_words), number_of_words), dtype=np.int16)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_vectors = np.zeros((len(input_words), context, number_of_words), dtype=np.int16)\n",
    "vectorized_labels = np.zeros((len(input_words), number_of_words), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "484b1d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"for i, input_w in enumerate(input_words):\\n    for j, w in enumerate(input_w):\\n        input_vectors[i, j, word2index[w]] = 1\\n        vectorized_labels[i, word2index[label_word[i]]] = 1\";\n",
       "                var nbb_formatted_code = \"for i, input_w in enumerate(input_words):\\n    for j, w in enumerate(input_w):\\n        input_vectors[i, j, word2index[w]] = 1\\n        vectorized_labels[i, word2index[label_word[i]]] = 1\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, input_w in enumerate(input_words):\n",
    "    for j, w in enumerate(input_w):\n",
    "        input_vectors[i, j, word2index[w]] = 1\n",
    "        vectorized_labels[i, word2index[label_word[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81b13b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-22 13:05:40.238234: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:40.290454: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:40.291551: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:40.293931: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-22 13:05:40.295224: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:40.296352: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:40.297417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:46.798747: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:46.800125: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:46.801295: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-22 13:05:46.802438: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9490 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:0b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"model = Sequential()\\nmodel.add(\\n    SimpleRNN(\\n        hidden_neurons,\\n        return_sequences=False,\\n        input_shape=(context, number_of_words),\\n        unroll=True,\\n    )\\n)\\nmodel.add(Dense(number_of_words))\\nmodel.add(Activation(output_nonlinearity))\\nmodel.compile(loss=error_function, optimizer=my_optimizer)\";\n",
       "                var nbb_formatted_code = \"model = Sequential()\\nmodel.add(\\n    SimpleRNN(\\n        hidden_neurons,\\n        return_sequences=False,\\n        input_shape=(context, number_of_words),\\n        unroll=True,\\n    )\\n)\\nmodel.add(Dense(number_of_words))\\nmodel.add(Activation(output_nonlinearity))\\nmodel.compile(loss=error_function, optimizer=my_optimizer)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    SimpleRNN(\n",
    "        hidden_neurons,\n",
    "        return_sequences=False,\n",
    "        input_shape=(context, number_of_words),\n",
    "        unroll=True,\n",
    "    )\n",
    ")\n",
    "model.add(Dense(number_of_words))\n",
    "model.add(Activation(output_nonlinearity))\n",
    "model.compile(loss=error_function, optimizer=my_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfc79d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<\n",
      " Cycle: 1\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1015\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1014\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1014\n",
      "Generating test from test index 1 with words ['would', 'anyone', 'ever']: \n",
      "THE COMPLETE RESULTING SENTENCE IS: would anyone ever besides\n",
      ">-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<\n",
      " Cycle: 2\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1014\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1014\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1014\n",
      "Generating test from test index 2 with words ['anyone', 'ever', 'eat']: \n",
      "THE COMPLETE RESULTING SENTENCE IS: anyone ever eat anything\n",
      ">-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<\n",
      " Cycle: 3\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1014\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1013\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1013\n",
      "Generating test from test index 5 with words ['anything', 'besides', 'breakfast']: \n",
      "THE COMPLETE RESULTING SENTENCE IS: anything besides breakfast breakfast\n",
      ">-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<\n",
      " Cycle: 4\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1013\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1013\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1013\n",
      "Generating test from test index 4 with words ['eat', 'anything', 'besides']: \n",
      "THE COMPLETE RESULTING SENTENCE IS: eat anything besides would\n",
      ">-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<>-<\n",
      " Cycle: 5\n",
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1013\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1012\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1012\n",
      "Generating test from test index 1 with words ['would', 'anyone', 'ever']: \n",
      "THE COMPLETE RESULTING SENTENCE IS: would anyone ever besides\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"for cycle in range(cycles):\\n    print(\\\">-<\\\" * 50)\\n    print(\\\" Cycle: %d\\\" % (cycle + 1))\\n    model.fit(\\n        input_vectors, vectorized_labels, batch_size=batch_size, epochs=epochs_per_cycle\\n    )\\n    test_index = np.random.randint(len(input_words))\\n    test_words = input_words[test_index]\\n    print(\\n        \\\"Generating test from test index %s with words %s: \\\" % (test_index, test_words)\\n    )\\n    input_for_test = np.zeros((1, context, number_of_words))\\n    for i, w in enumerate(test_words):\\n        input_for_test[0, i, word2index[w]] = 1\\n    predictions_all_matrix = model.predict(input_for_test, verbose=0)[0]\\n    predicted_word = index2word[np.argmax(predictions_all_matrix)]\\n    print(\\n        \\\"THE COMPLETE RESULTING SENTENCE IS: %s %s\\\"\\n        % (\\\" \\\".join(test_words), predicted_word)\\n    )\\nprint()  # put more cycles in if what you see here is gibberish\";\n",
       "                var nbb_formatted_code = \"for cycle in range(cycles):\\n    print(\\\">-<\\\" * 50)\\n    print(\\\" Cycle: %d\\\" % (cycle + 1))\\n    model.fit(\\n        input_vectors, vectorized_labels, batch_size=batch_size, epochs=epochs_per_cycle\\n    )\\n    test_index = np.random.randint(len(input_words))\\n    test_words = input_words[test_index]\\n    print(\\n        \\\"Generating test from test index %s with words %s: \\\" % (test_index, test_words)\\n    )\\n    input_for_test = np.zeros((1, context, number_of_words))\\n    for i, w in enumerate(test_words):\\n        input_for_test[0, i, word2index[w]] = 1\\n    predictions_all_matrix = model.predict(input_for_test, verbose=0)[0]\\n    predicted_word = index2word[np.argmax(predictions_all_matrix)]\\n    print(\\n        \\\"THE COMPLETE RESULTING SENTENCE IS: %s %s\\\"\\n        % (\\\" \\\".join(test_words), predicted_word)\\n    )\\nprint()  # put more cycles in if what you see here is gibberish\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for cycle in range(cycles):\n",
    "    print(\">-<\" * 50)\n",
    "    print(\" Cycle: %d\" % (cycle + 1))\n",
    "    model.fit(\n",
    "        input_vectors, vectorized_labels, batch_size=batch_size, epochs=epochs_per_cycle\n",
    "    )\n",
    "    test_index = np.random.randint(len(input_words))\n",
    "    test_words = input_words[test_index]\n",
    "    print(\n",
    "        \"Generating test from test index %s with words %s: \" % (test_index, test_words)\n",
    "    )\n",
    "    input_for_test = np.zeros((1, context, number_of_words))\n",
    "    for i, w in enumerate(test_words):\n",
    "        input_for_test[0, i, word2index[w]] = 1\n",
    "    predictions_all_matrix = model.predict(input_for_test, verbose=0)[0]\n",
    "    predicted_word = index2word[np.argmax(predictions_all_matrix)]\n",
    "    print(\n",
    "        \"THE COMPLETE RESULTING SENTENCE IS: %s %s\"\n",
    "        % (\" \".join(test_words), predicted_word)\n",
    "    )\n",
    "print()  # put more cycles in if what you see here is gibberish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145514b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
