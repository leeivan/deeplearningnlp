{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52520ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52829f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: gensim in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from gensim) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: pyfume in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim) (0.2.25)\n",
      "Requirement already satisfied: pandas in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from FuzzyTM>=0.4.0->gensim) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2022.7.1)\n",
      "Requirement already satisfied: fst-pso in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: simpful in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n",
      "Requirement already satisfied: requests in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2.28.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (3.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->simpful->pyfume->FuzzyTM>=0.4.0->gensim) (2022.12.7)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: pytouch in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (0.4.0)\n",
      "Requirement already satisfied: matplotlib>=3.2.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (3.7.0)\n",
      "Requirement already satisfied: torch>=1.4.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.13.1)\n",
      "Requirement already satisfied: flake8-copyright in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (0.2.4)\n",
      "Requirement already satisfied: torchmetrics in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (0.11.3)\n",
      "Requirement already satisfied: torchvision>=0.5.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.24.2)\n",
      "Requirement already satisfied: pytorch-lightning in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.9.4)\n",
      "Requirement already satisfied: hydra-core>=1.0.3 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.3.2)\n",
      "Requirement already satisfied: omegaconf>=2.0.2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (2.3.0)\n",
      "Requirement already satisfied: boto3 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.26.84)\n",
      "Requirement already satisfied: onnx in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.13.1)\n",
      "Requirement already satisfied: onnxruntime in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.14.1)\n",
      "Requirement already satisfied: nox>=2019.11.9 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (2022.11.21)\n",
      "Requirement already satisfied: black in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (23.1.0)\n",
      "Requirement already satisfied: opencv-python in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (4.7.0.72)\n",
      "Requirement already satisfied: isort in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (5.12.0)\n",
      "Requirement already satisfied: flake8 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (6.0.0)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytouch) (1.5.3)\n",
      "Requirement already satisfied: packaging in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from hydra-core>=1.0.3->pytouch) (23.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from hydra-core>=1.0.3->pytouch) (4.9.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from matplotlib>=3.2.1->pytouch) (9.4.0)\n",
      "Requirement already satisfied: argcomplete<3.0,>=1.9.4 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nox>=2019.11.9->pytouch) (2.0.5)\n",
      "Requirement already satisfied: virtualenv>=14 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nox>=2019.11.9->pytouch) (20.20.0)\n",
      "Requirement already satisfied: colorlog<7.0.0,>=2.6.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nox>=2019.11.9->pytouch) (6.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from omegaconf>=2.0.2->pytouch) (6.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pandas>=1.0.3->pytouch) (2022.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from torch>=1.4.0->pytouch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from torch>=1.4.0->pytouch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from torch>=1.4.0->pytouch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from torch>=1.4.0->pytouch) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from torch>=1.4.0->pytouch) (4.5.0)\n",
      "Requirement already satisfied: wheel in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->pytouch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->pytouch) (65.6.3)\n",
      "Requirement already satisfied: requests in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from torchvision>=0.5.0->pytouch) (2.28.2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tomli>=1.1.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from black->pytouch) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from black->pytouch) (8.1.3)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from black->pytouch) (0.11.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from black->pytouch) (1.0.0)\n",
      "Requirement already satisfied: platformdirs>=2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from black->pytouch) (3.0.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from boto3->pytouch) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from boto3->pytouch) (0.6.0)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.84 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from boto3->pytouch) (1.29.84)\n",
      "Requirement already satisfied: mccabe<0.8.0,>=0.7.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from flake8->pytouch) (0.7.0)\n",
      "Requirement already satisfied: pyflakes<3.1.0,>=3.0.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from flake8->pytouch) (3.0.1)\n",
      "Requirement already satisfied: pycodestyle<2.11.0,>=2.10.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from flake8->pytouch) (2.10.0)\n",
      "Requirement already satisfied: protobuf<4,>=3.20.2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from onnx->pytouch) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from onnxruntime->pytouch) (23.1.21)\n",
      "Requirement already satisfied: coloredlogs in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from onnxruntime->pytouch) (15.0.1)\n",
      "Requirement already satisfied: sympy in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from onnxruntime->pytouch) (1.11.1)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytorch-lightning->pytouch) (2023.3.0)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytorch-lightning->pytouch) (4.65.0)\n",
      "Requirement already satisfied: lightning-utilities>=0.6.0.post0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from pytorch-lightning->pytouch) (0.7.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.84->boto3->pytouch) (1.26.14)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (3.8.4)\n",
      "Requirement already satisfied: six>=1.5 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.2.1->pytouch) (1.16.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from virtualenv>=14->nox>=2019.11.9->pytouch) (0.3.6)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from virtualenv>=14->nox>=2019.11.9->pytouch) (3.9.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from coloredlogs->onnxruntime->pytouch) (10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->pytouch) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->pytouch) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->pytouch) (3.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from sympy->onnxruntime->pytouch) (1.2.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (1.3.3)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning->pytouch) (22.2.0)\n",
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting nltk\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/a6/0a/0d20d2c0f16be91b9fa32a77b76c60f9baf6eba419e5ef5deca17af9c582/nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/leeivan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"!pip install gensim\\n!pip install pytouch\\n!pip install nltk\\nimport torch\\nimport nltk\\nnltk.download('punkt')\";\n",
       "                var nbb_formatted_code = \"!pip install gensim\\n!pip install pytouch\\n!pip install nltk\\nimport torch\\nimport nltk\\n\\nnltk.download(\\\"punkt\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install pytouch\n",
    "!pip install nltk\n",
    "import torch\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6969959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"import math\\nimport numpy as np\\nfrom nltk.tokenize import sent_tokenize, word_tokenize\\nimport gensim\\nfrom gensim.models import Word2Vec\\nimport numpy as np\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nimport matplotlib.pyplot as plt\\nimport warnings\\n\\nwarnings.filterwarnings(action=\\\"ignore\\\")\\n\\n\\ndprint = 0  # prints outputs if set to 1, default=0\\n\\n# \\u2018text.txt\\u2019 file\\nsample = open(\\\"text.txt\\\", \\\"r\\\")\\ns = sample.read()\\n\\n# processing escape characters\\nf = s.replace(\\\"\\\\n\\\", \\\" \\\")\\n\\ndata = []\\n\\n# sentence parsing\\nfor i in sent_tokenize(f):\\n    temp = []\\n    # tokenize the sentence into words\\n    for j in word_tokenize(i):\\n        temp.append(j.lower())\\n    data.append(temp)\\n\\n# Creating Skip Gram model\\n# model2 = gensim.models.Word2Vec(data, min_count = 1, size = 512,window = 5, sg = 1)\\n# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\\nmodel2 = gensim.models.Word2Vec(data, min_count=1, vector_size=512, window=5, sg=1)\\n\\n# 1-The 2-black 3-cat 4-sat 5-on 6-the 7-couch 8-and 9-the 10-brown 11-dog 12-slept 13-on 14-the 15-rug.\\nword1 = \\\"black\\\"\\nword2 = \\\"brown\\\"\\npos1 = 2\\npos2 = 10\\na = model2.wv[word1]\\nb = model2.wv[word2]\\n\\nif dprint == 1:\\n    print(a)\\n\\n# compute cosine similarity\\ndot = np.dot(a, b)\\nnorma = np.linalg.norm(a)\\nnormb = np.linalg.norm(b)\\ncos = dot / (norma * normb)\\n\\naa = a.reshape(1, 512)\\nba = b.reshape(1, 512)\\ncos_lib = cosine_similarity(aa, ba)\";\n",
       "                var nbb_formatted_code = \"import math\\nimport numpy as np\\nfrom nltk.tokenize import sent_tokenize, word_tokenize\\nimport gensim\\nfrom gensim.models import Word2Vec\\nimport numpy as np\\nfrom sklearn.metrics.pairwise import cosine_similarity\\nimport matplotlib.pyplot as plt\\nimport warnings\\n\\nwarnings.filterwarnings(action=\\\"ignore\\\")\\n\\n\\ndprint = 0  # prints outputs if set to 1, default=0\\n\\n# \\u2018text.txt\\u2019 file\\nsample = open(\\\"text.txt\\\", \\\"r\\\")\\ns = sample.read()\\n\\n# processing escape characters\\nf = s.replace(\\\"\\\\n\\\", \\\" \\\")\\n\\ndata = []\\n\\n# sentence parsing\\nfor i in sent_tokenize(f):\\n    temp = []\\n    # tokenize the sentence into words\\n    for j in word_tokenize(i):\\n        temp.append(j.lower())\\n    data.append(temp)\\n\\n# Creating Skip Gram model\\n# model2 = gensim.models.Word2Vec(data, min_count = 1, size = 512,window = 5, sg = 1)\\n# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\\nmodel2 = gensim.models.Word2Vec(data, min_count=1, vector_size=512, window=5, sg=1)\\n\\n# 1-The 2-black 3-cat 4-sat 5-on 6-the 7-couch 8-and 9-the 10-brown 11-dog 12-slept 13-on 14-the 15-rug.\\nword1 = \\\"black\\\"\\nword2 = \\\"brown\\\"\\npos1 = 2\\npos2 = 10\\na = model2.wv[word1]\\nb = model2.wv[word2]\\n\\nif dprint == 1:\\n    print(a)\\n\\n# compute cosine similarity\\ndot = np.dot(a, b)\\nnorma = np.linalg.norm(a)\\nnormb = np.linalg.norm(b)\\ncos = dot / (norma * normb)\\n\\naa = a.reshape(1, 512)\\nba = b.reshape(1, 512)\\ncos_lib = cosine_similarity(aa, ba)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "\n",
    "dprint = 0  # prints outputs if set to 1, default=0\n",
    "\n",
    "# ‘text.txt’ file\n",
    "sample = open(\"text.txt\", \"r\")\n",
    "s = sample.read()\n",
    "\n",
    "# processing escape characters\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "\n",
    "data = []\n",
    "\n",
    "# sentence parsing\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []\n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "    data.append(temp)\n",
    "\n",
    "# Creating Skip Gram model\n",
    "# model2 = gensim.models.Word2Vec(data, min_count = 1, size = 512,window = 5, sg = 1)\n",
    "# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
    "model2 = gensim.models.Word2Vec(data, min_count=1, vector_size=512, window=5, sg=1)\n",
    "\n",
    "# 1-The 2-black 3-cat 4-sat 5-on 6-the 7-couch 8-and 9-the 10-brown 11-dog 12-slept 13-on 14-the 15-rug.\n",
    "word1 = \"black\"\n",
    "word2 = \"brown\"\n",
    "pos1 = 2\n",
    "pos2 = 10\n",
    "a = model2.wv[word1]\n",
    "b = model2.wv[word2]\n",
    "\n",
    "if dprint == 1:\n",
    "    print(a)\n",
    "\n",
    "# compute cosine similarity\n",
    "dot = np.dot(a, b)\n",
    "norma = np.linalg.norm(a)\n",
    "normb = np.linalg.norm(b)\n",
    "cos = dot / (norma * normb)\n",
    "\n",
    "aa = a.reshape(1, 512)\n",
    "ba = b.reshape(1, 512)\n",
    "cos_lib = cosine_similarity(aa, ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f11c56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"pe1=aa.copy()\\npe2=aa.copy()\\npe3=aa.copy()\\npaa=aa.copy()\\npba=ba.copy()\\nd_model=512\\nmax_print=d_model\\nmax_length=20\\n\\nfor i in range(0, max_print,2):\\n                pe1[0][i] = math.sin(pos1 / (10000 ** ((2 * i)/d_model)))\\n                paa[0][i] = (paa[0][i]*math.sqrt(d_model))+ pe1[0][i]\\n                pe1[0][i+1] = math.cos(pos1 / (10000 ** ((2 * i)/d_model)))\\n                paa[0][i+1] = (paa[0][i+1]*math.sqrt(d_model))+pe1[0][i+1]\\n                if dprint==1:\\n                        print(i,pe1[0][i],i+1,pe1[0][i+1])\\n                        print(i,paa[0][i],i+1,paa[0][i+1])\\n                        print(\\\"\\\\n\\\")\\n\\n#print(pe1)\\n# A  method in Pytorch using torch.exp and math.log :\\nmax_len=max_length                \\npe = torch.zeros(max_len, d_model)\\nposition = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\\ndiv_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\\npe[:, 0::2] = torch.sin(position * div_term)\\npe[:, 1::2] = torch.cos(position * div_term)\\n#print(pe[:, 0::2])\";\n",
       "                var nbb_formatted_code = \"pe1 = aa.copy()\\npe2 = aa.copy()\\npe3 = aa.copy()\\npaa = aa.copy()\\npba = ba.copy()\\nd_model = 512\\nmax_print = d_model\\nmax_length = 20\\n\\nfor i in range(0, max_print, 2):\\n    pe1[0][i] = math.sin(pos1 / (10000 ** ((2 * i) / d_model)))\\n    paa[0][i] = (paa[0][i] * math.sqrt(d_model)) + pe1[0][i]\\n    pe1[0][i + 1] = math.cos(pos1 / (10000 ** ((2 * i) / d_model)))\\n    paa[0][i + 1] = (paa[0][i + 1] * math.sqrt(d_model)) + pe1[0][i + 1]\\n    if dprint == 1:\\n        print(i, pe1[0][i], i + 1, pe1[0][i + 1])\\n        print(i, paa[0][i], i + 1, paa[0][i + 1])\\n        print(\\\"\\\\n\\\")\\n\\n# print(pe1)\\n# A  method in Pytorch using torch.exp and math.log :\\nmax_len = max_length\\npe = torch.zeros(max_len, d_model)\\nposition = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\\ndiv_term = torch.exp(\\n    torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\\n)\\npe[:, 0::2] = torch.sin(position * div_term)\\npe[:, 1::2] = torch.cos(position * div_term)\\n# print(pe[:, 0::2])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pe1 = aa.copy()\n",
    "pe2 = aa.copy()\n",
    "pe3 = aa.copy()\n",
    "paa = aa.copy()\n",
    "pba = ba.copy()\n",
    "d_model = 512\n",
    "max_print = d_model\n",
    "max_length = 20\n",
    "\n",
    "for i in range(0, max_print, 2):\n",
    "    pe1[0][i] = math.sin(pos1 / (10000 ** ((2 * i) / d_model)))\n",
    "    paa[0][i] = (paa[0][i] * math.sqrt(d_model)) + pe1[0][i]\n",
    "    pe1[0][i + 1] = math.cos(pos1 / (10000 ** ((2 * i) / d_model)))\n",
    "    paa[0][i + 1] = (paa[0][i + 1] * math.sqrt(d_model)) + pe1[0][i + 1]\n",
    "    if dprint == 1:\n",
    "        print(i, pe1[0][i], i + 1, pe1[0][i + 1])\n",
    "        print(i, paa[0][i], i + 1, paa[0][i + 1])\n",
    "        print(\"\\n\")\n",
    "\n",
    "# print(pe1)\n",
    "# A  method in Pytorch using torch.exp and math.log :\n",
    "max_len = max_length\n",
    "pe = torch.zeros(max_len, d_model)\n",
    "position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(\n",
    "    torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    ")\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "# print(pe[:, 0::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab1cb936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "black brown\n",
      "[[0.99951637]] word similarity\n",
      "[[0.8600013]] positional similarity\n",
      "[[0.96224964]] positional encoding similarity\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"for i in range(0, max_print, 2):\\n    pe2[0][i] = math.sin(pos2 / (10000 ** ((2 * i) / d_model)))\\n    pba[0][i] = (pba[0][i] * math.sqrt(d_model)) + pe2[0][i]\\n\\n    pe2[0][i + 1] = math.cos(pos2 / (10000 ** ((2 * i) / d_model)))\\n    pba[0][i + 1] = (pba[0][i + 1] * math.sqrt(d_model)) + pe2[0][i + 1]\\n\\n    if dprint == 1:\\n        print(i, pe2[0][i], i + 1, pe2[0][i + 1])\\n        print(i, paa[0][i], i + 1, paa[0][i + 1])\\n        print(\\\"\\\\n\\\")\\n\\nprint(word1, word2)\\ncos_lib = cosine_similarity(aa, ba)\\nprint(cos_lib, \\\"word similarity\\\")\\ncos_lib = cosine_similarity(pe1, pe2)\\nprint(cos_lib, \\\"positional similarity\\\")\\ncos_lib = cosine_similarity(paa, pba)\\nprint(cos_lib, \\\"positional encoding similarity\\\")\\n\\nif dprint == 1:\\n    print(word1)\\n    print(\\\"embedding\\\")\\n    print(aa)\\n    print(\\\"positional encoding\\\")\\n    print(pe1)\\n    print(\\\"encoded embedding\\\")\\n    print(paa)\\n\\n    print(word2)\\n    print(\\\"embedding\\\")\\n    print(ba)\\n    print(\\\"positional encoding\\\")\\n    print(pe2)\\n    print(\\\"encoded embedding\\\")\\n    print(pba)\";\n",
       "                var nbb_formatted_code = \"for i in range(0, max_print, 2):\\n    pe2[0][i] = math.sin(pos2 / (10000 ** ((2 * i) / d_model)))\\n    pba[0][i] = (pba[0][i] * math.sqrt(d_model)) + pe2[0][i]\\n\\n    pe2[0][i + 1] = math.cos(pos2 / (10000 ** ((2 * i) / d_model)))\\n    pba[0][i + 1] = (pba[0][i + 1] * math.sqrt(d_model)) + pe2[0][i + 1]\\n\\n    if dprint == 1:\\n        print(i, pe2[0][i], i + 1, pe2[0][i + 1])\\n        print(i, paa[0][i], i + 1, paa[0][i + 1])\\n        print(\\\"\\\\n\\\")\\n\\nprint(word1, word2)\\ncos_lib = cosine_similarity(aa, ba)\\nprint(cos_lib, \\\"word similarity\\\")\\ncos_lib = cosine_similarity(pe1, pe2)\\nprint(cos_lib, \\\"positional similarity\\\")\\ncos_lib = cosine_similarity(paa, pba)\\nprint(cos_lib, \\\"positional encoding similarity\\\")\\n\\nif dprint == 1:\\n    print(word1)\\n    print(\\\"embedding\\\")\\n    print(aa)\\n    print(\\\"positional encoding\\\")\\n    print(pe1)\\n    print(\\\"encoded embedding\\\")\\n    print(paa)\\n\\n    print(word2)\\n    print(\\\"embedding\\\")\\n    print(ba)\\n    print(\\\"positional encoding\\\")\\n    print(pe2)\\n    print(\\\"encoded embedding\\\")\\n    print(pba)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, max_print, 2):\n",
    "    pe2[0][i] = math.sin(pos2 / (10000 ** ((2 * i) / d_model)))\n",
    "    pba[0][i] = (pba[0][i] * math.sqrt(d_model)) + pe2[0][i]\n",
    "\n",
    "    pe2[0][i + 1] = math.cos(pos2 / (10000 ** ((2 * i) / d_model)))\n",
    "    pba[0][i + 1] = (pba[0][i + 1] * math.sqrt(d_model)) + pe2[0][i + 1]\n",
    "\n",
    "    if dprint == 1:\n",
    "        print(i, pe2[0][i], i + 1, pe2[0][i + 1])\n",
    "        print(i, paa[0][i], i + 1, paa[0][i + 1])\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(word1, word2)\n",
    "cos_lib = cosine_similarity(aa, ba)\n",
    "print(cos_lib, \"word similarity\")\n",
    "cos_lib = cosine_similarity(pe1, pe2)\n",
    "print(cos_lib, \"positional similarity\")\n",
    "cos_lib = cosine_similarity(paa, pba)\n",
    "print(cos_lib, \"positional encoding similarity\")\n",
    "\n",
    "if dprint == 1:\n",
    "    print(word1)\n",
    "    print(\"embedding\")\n",
    "    print(aa)\n",
    "    print(\"positional encoding\")\n",
    "    print(pe1)\n",
    "    print(\"encoded embedding\")\n",
    "    print(paa)\n",
    "\n",
    "    print(word2)\n",
    "    print(\"embedding\")\n",
    "    print(ba)\n",
    "    print(\"positional encoding\")\n",
    "    print(pe2)\n",
    "    print(\"encoded embedding\")\n",
    "    print(pba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ca802b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2424678493.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[14], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    pe[0][i]=math.sin(pos/(10000 * *((2 * i)/d_model )))\u001b[0m\n\u001b[0m                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot parse: 4:39:         pe[0][i]=math.sin(pos/(10000 * *((2 * i)/d_model )))\n",
      "Traceback (most recent call last):\n",
      "  File \"/nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages/lab_black.py\", line 218, in format_cell\n",
      "    formatted_code = _format_code(cell)\n",
      "  File \"/nfs/workspaces/virtualenvs/deeplearningnlp/lib/python3.10/site-packages/lab_black.py\", line 29, in _format_code\n",
      "    return format_str(src_contents=code, mode=FileMode())\n",
      "  File \"src/black/__init__.py\", line 1079, in format_str\n",
      "  File \"src/black/__init__.py\", line 1089, in _format_str_once\n",
      "  File \"src/black/parsing.py\", line 127, in lib2to3_parse\n",
      "black.parsing.InvalidInput: Cannot parse: 4:39:         pe[0][i]=math.sin(pos/(10000 * *((2 * i)/d_model )))\n"
     ]
    }
   ],
   "source": [
    "def positional_encoding(pos,pe):\n",
    "    for i in range (0,512,2):\n",
    "\n",
    "        pe[0][i]=math.sin(pos/(10000 * *((2 * i)/d_model )))\n",
    "\n",
    "        pe[0][i+1]=math.cos(pos /(10000 * *((2 * i)/d_model)))\n",
    "        \n",
    "return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79787f14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
